{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=5>\n",
    "\t\t<div align=center>\n",
    "\t\t\t<font face=\"IranNastaliq\" size=30>\n",
    "\t\t\t\t<p></p>\n",
    "\t\t\t\t<p></p>\n",
    "به نام خدا\n",
    "\t\t\t\t<p></p>\n",
    "\t\t\t</font>\n",
    "\t\t\t<p></p>\n",
    "\t\t\t<font color=blue>\n",
    "پروژه ی filler\n",
    "            </font>\n",
    "\t\t\t<br />\n",
    "\t\t\t<br />\n",
    "دی ماه 97\n",
    "\t\t</div>\n",
    "\t\t<hr/>\n",
    "\t\t<font color=red size=6>\n",
    "\t\t\t<br />\n",
    "\t\t\t<div align=center>\n",
    "while loop\n",
    "            </div>        \n",
    "\t\t</font>\n",
    "\t\t<br />\n",
    "\t\t<div align=center>\n",
    " مهدی غزنوی\n",
    "        </div>\n",
    "\t\t<hr />\n",
    "\t\t<style type=\"text/css\" scoped>\n",
    "        p{\n",
    "        border: 1px solid #a2a9b1;background-color: #f8f9fa;display: inline-block;\n",
    "        };\n",
    "        </style>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "    <font face=\"XB Zar\" size=5>\n",
    "        یکی از چابش های اصلی در tensorflow تکرار یک کار است. دلیل چالشی بودن موضوع این است که tensorflow با ساختن یک گراف از اعمال مورد نظر ما و اجرای آن کار می کند. مشکلی که در اینجا به وجود می آید این است که ممکن بخواهیم تعداد اجرای یک عمل بر حسب ورودی متفاوت باشد؛ در اینصورت گراف operationهای ما برای ورودی های مختلف باید فرق کند.<br/>\n",
    "        راه حل tensorflow برای این موضوع استفاده از tf.while_loop است. به صورت خلاصه tf.while_loop با گرفتن یک body و یک condition درست مانند یک loop عادی تا زمانی که cond برقرار است body را انجام می دهد \n",
    "    </font> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def while_loop(cond,\n",
    "               body,\n",
    "               loop_vars,\n",
    "               shape_invariants=None,\n",
    "               parallel_iterations=10,\n",
    "               back_prop=True,\n",
    "               swap_memory=False,\n",
    "               name=None,\n",
    "               maximum_iterations=None,\n",
    "               return_same_structure=False):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "    <font face=\"XB Zar\" size=5>\n",
    "        body و cond هر دو توابعی هستند که loop_vars به عنوان ورودی به آنها داده می شود. در تابع بالا loop_vars ورودی های اولیه به body و condition است. در مراحل بعدی اجرای حلقه نیز ورودی ها باید ساختاری مشابه loop_vars داشته باشند. به عبارت دیگر خروجی های body نیز باید هم ساختار loop_vars باشد.<br/>\n",
    "    </font> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "    <font face=\"XB Zar\" size=5>\n",
    "        tensorflow این قابلیت را به ما داده است که در body خروجی هایی با ساختار متفاوت با loop_vars داشته باشیم. به این منظور می توانیم از shape_varients استفاده کنیم. در shape_varients باید برای هرکدام از عاصر loop_vars یک shape مشخص کنیم. این shape متفاوت کلی تر از shape عضو متناظر در loop_vars باشد. مثال زیر به درک بهتر کاربرد این loop_varients کمک می کند.<br/>\n",
    "        برابر بودن خروجی کل while_loop با ورودی آن را نیز می توان با return_same_structure کنترل کرد.\n",
    "    </font> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'while/Exit:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'while/Exit_1:0' shape=(?, 2) dtype=float32>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "i0 = tf.constant(0)\n",
    "m0 = tf.ones([2, 2])\n",
    "c = lambda i, m: i < 10 #condition\n",
    "b = lambda i, m: [i+1, tf.concat([m, m], axis=0)] #body\n",
    "tf.while_loop(\n",
    "    c, b, loop_vars=[i0, m0],\n",
    "    shape_invariants=[i0.get_shape(), tf.TensorShape([None, 2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "    <font face=\"XB Zar\" size=5>\n",
    "        نحوه ی کار while_loop به این صورت است که ابتدا گراف body و condition را تشکیل می دهد و سپس خروجی ها را به ورودی ها وصل می کند. اجرای گراف و تولید خروجی ها ممکن است قابلیت اجرا به صورت موازی را داشته باشد. در ورودی while_loop می توان حداکثر تعداد پردازش های موازی به هنوان parallel_iterations مشخص کرد.\n",
    "    </font> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "    <font face=\"XB Zar\" size=5>\n",
    "        گاهی اوقات ممکن است یک treshhold برای تعداد عملیات هایمان داشته باشیم. برای مثال با وجود اینکه پایان جملات را با EOS مشخص می کنیم قالبا یک طول بیشینه نیز برای آن در نظر می گیریم که در صورتی که برنامه بیش از آن مقدار token تولید کرد جمله را خاتمه می دهیم.<br/>\n",
    "        این treshhold را می توانیم در maximum_iterations تعیین کنیم.\n",
    "    </font> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "    <font face=\"XB Zar\" size=5>\n",
    "        <b>نکته</b>: توابع body و cond تنها یک بار و در زمان ساختن گراف صدا زده می شوند.\n",
    "    </font> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "n = 10000\n",
    "x = tf.constant(list(range(n)))\n",
    "c = lambda i, x: i < n\n",
    "b = lambda i, x: (tf.Print(i + 1, [i]), tf.Print(x + 1, [i], \"x:\"))\n",
    "i, out = tf.while_loop(c, b, (0, x))\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(i))  # prints [0] ... [9999]\n",
    "\n",
    "    # The following line may increment the counter and x in parallel.\n",
    "    # The counter thread may get ahead of the other thread, but not the\n",
    "    # other way around. So you may see things like\n",
    "    # [9996] x:[9987]\n",
    "    # meaning that the counter thread is on iteration 9996,\n",
    "    # while the other thread is on iteration 9987\n",
    "    print(sess.run(out).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "    <font face=\"XB Zar\" size=5>\n",
    "        اکنون بیایید مثال بالا از صفحه ی while_loop در سایت tensorflow را بررسی کنیم.<br/>\n",
    "        چون خروجی x و i ربطی به هم ندارند پس با اجرای (sess.run(i تنها قسمت اول b اجرا می شود و درنتیجه خروجی به صورت:<br/>[0]<br/> ... <br/>[9999]<br/>(sess.run(x نیز به صورت مشابه عمل می کند. \n",
    "    </font> \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
